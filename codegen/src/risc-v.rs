/*
 * Permission is hereby granted, free of charge, to any human obtaining a copy of this software and associated documentation files
 * (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify,
 * merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit humans to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
 * OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
 * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 */

extern crate proc_macro;

use {
    proc_macro::{Delimiter, Group, Ident, TokenStream, TokenTree},
};

#[derive(Clone, Copy, Debug)]
pub(crate) struct ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬<'áµ‰Ë£áµ—Ê³áµƒ> {
    ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾: Option<ğ«ğ¢ğ¬ğœ_ğ¯_ğ¦ğ¨ğğ>,
    ğ—‹ğ—_ğ–ºğ–»ğ—‚: Option<ğ«ğ¢ğ¬ğœ_ğ¯_ğšğ›ğ¢>,
    ğ–¾ğ—‘ğ—ğ—‹ğ–º_ğ–ºğ—ğ—ğ—‹ğ—‚ğ–»ğ—ğ—ğ–¾ğ—Œ: &'áµ‰Ë£áµ—Ê³áµƒ super::ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğğ±ğ­ğ«ğš_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬,
}

#[derive(Clone, Copy, Debug, Eq, PartialEq)]
pub(crate) enum ğ«ğ¢ğ¬ğœ_ğ¯_ğ¦ğ¨ğğ {
    ğ”¯ğ”³32ğ”¢ = 0,
    ğ”¯ğ”³32ğ”¦ = 1,
    ğ”¯ğ”³64ğ”¦ = 2
}

#[derive(Clone, Copy, Debug, Eq, PartialEq)]
pub(crate) enum ğ«ğ¢ğ¬ğœ_ğ¯_ğšğ›ğ¢ {
    ğ”¢ğ”ğ”Ÿğ”¦ = 0,
    ğ”²ğ”ğ”Ÿğ”¦ = 1
}

impl<'áµ‰Ë£áµ—Ê³áµƒ> ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬<'áµ‰Ë£áµ—Ê³áµƒ> {
    pub(crate) fn new(
        input: &mut impl Iterator<Item = TokenTree>,
        ğ–¾ğ—‘ğ—ğ—‹ğ–º_ğ–ºğ—ğ—ğ—‹ğ—‚ğ–»ğ—ğ—ğ–¾ğ—Œ: &'áµ‰Ë£áµ—Ê³áµƒ super::ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğğ±ğ­ğ«ğš_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬,
    ) -> Result<Self, &'static str> {
        let mut result: Self = ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬ {
            ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾: None,
            ğ—‹ğ—_ğ–ºğ–»ğ—‚: None,
            ğ–¾ğ—‘ğ—ğ—‹ğ–º_ğ–ºğ—ğ—ğ—‹ğ—‚ğ–»ğ—ğ—ğ–¾ğ—Œ,
        };
        let mut process = |identifier: &Ident| -> Result<(), &'static str> {
            match identifier.to_string().as_ref() {
                "ğ”¯ğ”³32ğ”¢" => {
                    if result.ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾.is_some() {
                        return Err("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–—ğ–ğ–˜ğ–ˆğ–›_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” duplicated address size.\");");
                    } else {
                        result.ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾ = Some(ğ«ğ¢ğ¬ğœ_ğ¯_ğ¦ğ¨ğğ::ğ”¯ğ”³32ğ”¢)
                    }
                }
                "ğ”¯ğ”³32ğ”¦" => {
                    if result.ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾.is_some() {
                        return Err("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–—ğ–ğ–˜ğ–ˆğ–›_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” duplicated address size.\");");
                    } else {
                        result.ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾ = Some(ğ«ğ¢ğ¬ğœ_ğ¯_ğ¦ğ¨ğğ::ğ”¯ğ”³32ğ”¦)
                    }
                }
                "ğ”¯ğ”³64ğ”¦" => {
                    if result.ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾.is_some() {
                        return Err("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–—ğ–ğ–˜ğ–ˆğ–›_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” duplicated address size.\");");
                    } else {
                        result.ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾ = Some(ğ«ğ¢ğ¬ğœ_ğ¯_ğ¦ğ¨ğğ::ğ”¯ğ”³64ğ”¦)
                    }
                }
                "ğ”¢ğ”ğ”Ÿğ”¦" => {
                    if result.ğ—‹ğ—_ğ–ºğ–»ğ—‚.is_some() {
                        return Err("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–—ğ–ğ–˜ğ–ˆğ–›_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” duplicated address size.\");");
                    } else {
                        result.ğ—‹ğ—_ğ–ºğ–»ğ—‚ = Some(ğ«ğ¢ğ¬ğœ_ğ¯_ğšğ›ğ¢::ğ”¢ğ”ğ”Ÿğ”¦)
                    }
                }
                "ğ”²ğ”ğ”Ÿğ”¦" => {
                    if result.ğ—‹ğ—_ğ–ºğ–»ğ—‚.is_some() {
                        return Err("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–—ğ–ğ–˜ğ–ˆğ–›_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” duplicated address size.\");");
                    } else {
                        result.ğ—‹ğ—_ğ–ºğ–»ğ—‚ = Some(ğ«ğ¢ğ¬ğœ_ğ¯_ğšğ›ğ¢::ğ”²ğ”ğ”Ÿğ”¦)
                    }
                }
                _ => return Err("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–—ğ–ğ–˜ğ–ˆğ–›_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” unknown token.\");"),
            }
            Ok(())
        };
        for token_tree in input {
            match &token_tree {
                TokenTree::Ident(identifier) => {
                    process(identifier)?;
                }
                TokenTree::Group(group) if matches!(group.delimiter(), Delimiter::None) => {
                    for token_tree in group.stream().into_iter() {
                        let TokenTree::Ident(identifier) = &token_tree else {
                            return Err("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–—ğ–ğ–˜ğ–ˆğ–›_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” attributes group includes unknown item.\");")
			};
                        process(identifier)?;
                    }
                }
                _ => return Err("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–—ğ–ğ–˜ğ–ˆğ–›_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” attributes group includes unknown item.\");"),
            }
        }
        if let Some(ref ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾) = result.ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾ {
            if result.ğ—‹ğ—_ğ–ºğ–»ğ—‚.is_none() {
                result.ğ—‹ğ—_ğ–ºğ–»ğ—‚ = Some(match ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾ {
                    ğ«ğ¢ğ¬ğœ_ğ¯_ğ¦ğ¨ğğ::ğ”¯ğ”³32ğ”¢ => ğ«ğ¢ğ¬ğœ_ğ¯_ğšğ›ğ¢::ğ”¢ğ”ğ”Ÿğ”¦,
                    _ => ğ«ğ¢ğ¬ğœ_ğ¯_ğšğ›ğ¢::ğ”²ğ”ğ”Ÿğ”¦
                });
            }
        }
        Ok(result)
    }
}

pub(crate) fn filter_riscv_markers_iterable(
    output: &mut impl Extend<TokenTree>,
    output_extra: &mut Option<TokenStream>,
    input: &mut impl Iterator<Item = TokenTree>,
    attributes: ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬,
) {
    fn emit_tokens(
        output: &mut impl Extend<TokenTree>,
        output_extra: &mut Option<TokenStream>,
        tokens: impl IntoIterator<Item = TokenTree> + Clone,
    ) {
        if let Some(output) = output_extra.as_mut() {
            output.extend(tokens.clone());
        }
        output.extend(tokens)
    }

    fn emit_or_expand_token(
        output: &mut impl Extend<TokenTree>,
        output_extra: &mut Option<TokenStream>,
        token: TokenTree,
        attributes: ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬,
    ) {
        let TokenTree::Ident(ref ident) = token else {
            return emit_tokens(output, output_extra, [token]);
        };

        match ident.to_string().as_ref() {
            "ğ”¸ğ•¦ğ•¥ğ• ğ•€ğ•ğ•¡ğ•ğ•–ğ•ğ•–ğ•Ÿğ•¥ğ•–ğ••ğ•‹ğ•£ğ•’ğ•šğ•¥" => {
                todo!();
            }
            _ => emit_tokens(output, output_extra, [token])
        }
    }

    let mut instructions_interface: Option<TokenStream> = None;
    let mut last_token: Option<TokenTree> = None;
    for token in input {
        if let Some(unwrapped_token) = last_token.take() {
            match token {
                TokenTree::Group(mut data_group_to_process) if matches!(data_group_to_process.delimiter(), Delimiter::Bracket) => {
                    let unwrapped_token_str = unwrapped_token.to_string();
                    let unwrapped_token_ref = unwrapped_token_str.as_ref();
                    match marker_is_compatible(unwrapped_token_ref, attributes) {
                        (Some(true), attributes) => filter_riscv_markers_iterable(
                            output,
                            output_extra,
                            &mut data_group_to_process.stream().into_iter(),
                            attributes,
                        ),
                        (Some(false), _) => (),
                        (None, _) if unwrapped_token_ref == "ğ•€ğ•Ÿğ•¤ğ•¥ğ•£ğ•¦ğ•”ğ•¥ğ•šğ• ğ•Ÿğ•¤ğ•€ğ•Ÿğ•¥ğ•–ğ•£ğ•—ğ•’ğ•”ğ•–" =>
                        {
                            if instructions_interface.is_some() {
                                panic!("Two ğ•€ğ•Ÿğ•¤ğ•¥ğ•£ğ•¦ğ•”ğ•¥ğ•šğ• ğ•Ÿğ•¤ğ•€ğ•Ÿğ•¥ğ•–ğ•£ğ•—ğ•’ğ•”ğ•– markers detected!");
                            }
                            instructions_interface.replace(TokenStream::new());
                            filter_riscv_markers_iterable(
                                output,
                                &mut instructions_interface,
                                &mut data_group_to_process.stream().into_iter(),
                                attributes,
                            );
                            output_extra.as_mut().map({
                                let instructions_interface = instructions_interface.clone();
                                |output| output.extend(instructions_interface.unwrap())
                            });
                        }
                        (None, _) => {
                            emit_or_expand_token(output, output_extra, unwrapped_token, attributes);
                            let filered_content = [filter_riscv_markers_group(&mut data_group_to_process, attributes)];
                            emit_tokens(output, output_extra, filered_content);
                        }
                    }
                }
                TokenTree::Group(mut data_group_to_process) => {
                    emit_or_expand_token(output, output_extra, unwrapped_token, attributes);
                    let filered_content = [filter_riscv_markers_group(&mut data_group_to_process, attributes)];
                    emit_tokens(output, output_extra, filered_content);
                }
                TokenTree::Ident(_) => {
                    emit_or_expand_token(output, output_extra, unwrapped_token, attributes);
                    last_token = Some(token)
                }
                _ => {
                    emit_or_expand_token(output, output_extra, unwrapped_token, attributes);
                    emit_tokens(output, output_extra, [token]);
                }
            }
        } else if let TokenTree::Ident(_) = token {
            last_token = Some(token)
        } else if let TokenTree::Group(mut data_group_to_process) = token {
            let filered_content = [filter_riscv_markers_group(&mut data_group_to_process, attributes)];
            emit_tokens(output, output_extra, filered_content)
        } else {
            emit_tokens(output, output_extra, [token])
        }
    }
    if let Some(unwrapped_token) = last_token.take() {
        emit_or_expand_token(output, output_extra, unwrapped_token, attributes);
    }
    if let Some(instructions_interface) = instructions_interface {
        todo!();
    }
}

fn filter_riscv_markers_group(
    input: &mut Group, attributes: ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬
) -> TokenTree {
    let mut content = TokenStream::new();
    filter_riscv_markers_iterable(&mut content, &mut None, &mut input.stream().into_iter(), attributes);
    Group::new(input.delimiter(), content).into()
}

fn marker_is_compatible<'áµ‰Ë£áµ—Ê³áµƒ>(
    marker: &str,
    attributes: ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬<'áµ‰Ë£áµ—Ê³áµƒ>,
) -> (Option<bool>, ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬<'áµ‰Ë£áµ—Ê³áµƒ>) {
    match marker {
        "Îğ”¯ğ”³32ğ”¢" => (Some(attributes.ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾.unwrap() == ğ«ğ¢ğ¬ğœ_ğ¯_ğ¦ğ¨ğğ::ğ”¯ğ”³32ğ”¢), attributes),
        "Î§ğ”¯ğ”³32ğ”¢" => (Some(attributes.ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾.unwrap() != ğ«ğ¢ğ¬ğœ_ğ¯_ğ¦ğ¨ğğ::ğ”¯ğ”³32ğ”¢), attributes),
        "Îğ”¯ğ”³32" => (Some(attributes.ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾.unwrap() != ğ«ğ¢ğ¬ğœ_ğ¯_ğ¦ğ¨ğğ::ğ”¯ğ”³64ğ”¦), attributes),
        "Îğ”¯ğ”³64" => (Some(attributes.ğ—‹ğ—_ğ—†ğ—ˆğ–½ğ–¾.unwrap() == ğ«ğ¢ğ¬ğœ_ğ¯_ğ¦ğ¨ğğ::ğ”¯ğ”³64ğ”¦), attributes),
        "Îğ”¢ğ”ğ”Ÿğ”¦" => (Some(attributes.ğ—‹ğ—_ğ–ºğ–»ğ—‚.unwrap() == ğ«ğ¢ğ¬ğœ_ğ¯_ğšğ›ğ¢::ğ”¢ğ”ğ”Ÿğ”¦), attributes),
        "Îğ”²ğ”ğ”Ÿğ”¦" => (Some(attributes.ğ—‹ğ—_ğ–ºğ–»ğ—‚.unwrap() == ğ«ğ¢ğ¬ğœ_ğ¯_ğšğ›ğ¢::ğ”²ğ”ğ”Ÿğ”¦), attributes),
        _ => (None, attributes),
    }
}
