/*
 * Permission is hereby granted, free of charge, to any human obtaining a copy of this software and associated documentation files
 * (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify,
 * merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit humans to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
 * OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
 * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 */

#![allow(uncommon_codepoints)]
#![allow(non_camel_case_types)]
#![allow(non_upper_case_globals)]

extern crate proc_macro;

#[macro_use]
extern crate maplit;

use futures::TryStreamExt;
use lazy_static::lazy_static;
use proc_macro::{Delimiter, Group, Ident, TokenStream, TokenTree};
use sqlx::{Connection, Row};

// Note: the use of that macro is a bit unusial. It works like this:
//     ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! {
//         ğ“¼ğ“¸ğ“¶ğ“®_ğ“¸ğ“½ğ“±ğ“®ğ“»_ğ“¶ğ“ªğ“¬ğ“»ğ“¸! {
//             [ğ“ªğ“­ğ“­ğ“»ğ“®ğ“¼ğ“¼_ğ“¼ğ“²ğ”ƒğ“® ğ“­ğ“ªğ“½ğ“ª_ğ“¼ğ“²ğ”ƒğ“® ğ“®ğ”ğ“½ğ“»ğ“ª_ğ“»ğ“®ğ“¼ğ“½ğ“»ğ“²ğ“¬ğ“½ğ“²ğ“¸ğ“·ğ“¼â€¦]
//             [â€¦ ğ“ªğ“­ğ“­ğ“²ğ“­ğ“½ğ“²ğ“¸ğ“·ğ“ªğ“µ ğ“¾ğ“·ğ“¯ğ“²ğ“µğ“½ğ“®ğ“»ğ“®ğ“­ ğ“­ğ“ªğ“½ğ“ª â€¦]
//             â€¦ ğ“ªğ“­ğ“­ğ“²ğ“­ğ“½ğ“²ğ“¸ğ“·ğ“ªğ“µ ğ“­ğ“ªğ“½ğ“ª ğ“½ğ“¸ ğ“¯ğ“²ğ“µğ“½ğ“®ğ“» â€¦
//         }
//    }
// ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! first moves filtered data to unfiltered one, then removes square brackets and expands ğ“¼ğ“¸ğ“¶ğ“®_ğ“¸ğ“½ğ“±ğ“®ğ“»_ğ“¶ğ“ªğ“¬ğ“»ğ“¸!
// We couldn't use â€œmore obviousâ€ alternative where ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! would be called from the ğ“¼ğ“¸ğ“¶ğ“®_ğ“¸ğ“½ğ“±ğ“®ğ“»_ğ“¶ğ“ªğ“¬ğ“»ğ“¸! because in Rust
// macro can only be called in certain, limited, positions and sometimes (e.g. in ğ–‰ğ–Šğ–‹ğ–ğ–“ğ–Š_ğ–†ğ–˜ğ–˜ğ–Šğ–’ğ–‡ğ–‘ğ–Šğ–—_ğ–™ğ–—ğ–†ğ–ğ–™) we need to filter data in
// some positions where this call is not allowed.
//
// Supported markers:
//     â„œ16 â€” 8086 data (ğ“­ğ“ªğ“½ğ“ª_ğ“¼ğ“²ğ”ƒğ“® == ğ”ğ”¡ğ”¡ğ”¯16)
//     â„œ32 â€” 80386 data (ğ“­ğ“ªğ“½ğ“ª_ğ“¼ğ“²ğ”ƒğ“® == ğ”ğ”¡ğ”¡ğ”¯32, ğ“ªğ“­ğ“­ğ“»ğ“®ğ“¼ğ“¼_ğ“¼ğ“²ğ”ƒğ“® == ğ”ğ”¡ğ”¡ğ”¯64)
//     Î16 â€” 8086 address (ğ“ªğ“­ğ“­ğ“»ğ“®ğ“¼ğ“¼_ğ“¼ğ“²ğ”ƒğ“® == ğ”ğ”¡ğ”¡ğ”¯16)
//     Î32 â€” 80386 address (ğ“ªğ“­ğ“­ğ“»ğ“®ğ“¼ğ“¼_ğ“¼ğ“²ğ”ƒğ“® == ğ”ğ”¡ğ”¡ğ”¯32)
//     Î86 â€” â€œlegacyâ€ â‚“86 mode (ğ“ªğ“­ğ“­ğ“»ğ“®ğ“¼ğ“¼_ğ“¼ğ“²ğ”ƒğ“® â‰  ğ”ğ”¡ğ”¡ğ”¯64)
//     Î64 â€” â‚“86_64 mode (ğ“ªğ“­ğ“­ğ“»ğ“®ğ“¼ğ“¼_ğ“¼ğ“²ğ”ƒğ“® == ğ”ğ”¡ğ”¡ğ”¯64)
//     Îğ”¦ğ”· â€” expaded if â‚“ğ”¦ğ”· mode requested.
//     Î§ğ”¦ğ”· â€” expaded if â‚“ğ”¦ğ”· mode anot requested.
//     Îğ”·ğ”· â€” expaded if ğ”ğ”¡ğ”¡ğ”¯64 with â‚áµ¥â‚“512 mode requested.
//     Î§ğ”·ğ”· â€” expaded if ğ”ğ”¡ğ”¡ğ”¯64 with â‚áµ¥â‚“512 mode not requested.
#[proc_macro]
pub fn ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜(items: TokenStream) -> TokenStream {
    let mut iter = items.into_iter();
    let macro_name = if let Some(TokenTree::Ident(macro_name)) = iter.next() {
        macro_name
    } else {
        return "compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” couldn't find the name of nested macro.\");"
            .parse()
            .unwrap();
    };
    let exclamation_mark = if let Some(TokenTree::Punct(exclamation_mark)) = iter.next() {
        if exclamation_mark.as_char() == '!' {
            exclamation_mark
        } else {
            return "compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” couldn't find ! after the name of nested macro.\");"
                .parse()
                .unwrap();
        }
    } else {
        return "compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” couldn't find ! after the name of nested macro.\");"
            .parse()
            .unwrap();
    };
    let main_group = if let Some(TokenTree::Group(main_group)) = iter.next() {
        if let Delimiter::Brace = main_group.delimiter() {
            main_group
        } else {
            return "compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” main group should use braces.\");"
                .parse()
                .unwrap();
        }
    } else {
        return "compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” couldn't find main group to process.\");"
            .parse()
            .unwrap();
    };
    if iter.next().is_some() {
        return "compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” spurious tokens after main group.\");"
            .parse()
            .unwrap();
    }

    let mut main_group_iter = main_group.stream().into_iter();
    let attributes_group = if let Some(TokenTree::Group(attributes_group)) = main_group_iter.next() {
        if let Delimiter::Bracket = attributes_group.delimiter() {
            attributes_group
        } else {
            return "compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” attributes_group group should use brackets.\");"
                .parse()
                .unwrap();
        }
    } else {
        return "compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” couldn't find attributes group to process.\");"
            .parse()
            .unwrap();
    };

    let mut attributes_iter = attributes_group.stream().into_iter();
    let attributes = ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬::new(&mut attributes_iter);
    let attributes = match attributes {
        Ok(attributes) => attributes,
        Err(err) => return err.parse().unwrap(),
    };

    let mut unfiletered_data_group_iter = main_group_iter.clone();
    let unfiletered_data_group = match unfiletered_data_group_iter.next() {
        Some(TokenTree::Group(unfiletered_data_group)) if matches!(unfiletered_data_group.delimiter(), Delimiter::Bracket) => {
            main_group_iter = unfiletered_data_group_iter;
            Some(unfiletered_data_group)
        }
        _ => None,
    };
    let mut arguments = TokenStream::new();
    arguments.extend([TokenTree::Group(attributes_group)]);
    if let Some(unfiletered_data_group) = unfiletered_data_group {
        arguments.extend([TokenTree::Group(unfiletered_data_group)]);
    }
    filter_x86_markers_iterable(&mut arguments, &mut main_group_iter, attributes);
    let mut result = TokenStream::new();
    result.extend([
        TokenTree::Ident(macro_name),
        TokenTree::Punct(exclamation_mark),
        Into::<TokenTree>::into(Group::new(Delimiter::Brace, arguments)),
    ]);
    result
}

#[derive(Clone, Copy, Default, Debug)]
struct ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬ {
    ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾: Option<core::num::NonZeroI8>,
    ğ–½ğ–ºğ—ğ–º_ğ—Œğ—‚ğ—“ğ–¾: Option<core::num::NonZeroI8>,
    â‚“ğ—‚ğ—“: Option<i8>,
    ğ–ºğ—ğ—‘ğŸ§ğŸ£ğŸ¤: Option<bool>,
}

impl ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬ {
    fn new(input: &mut impl Iterator<Item = TokenTree>) -> Result<Self, &'static str> {
        let mut result: Self = Default::default();
        let mut process = |identifier: &Ident| -> Option<&'static str> {
            match identifier.to_string().as_str() {
                "ğ”ğ”¡ğ”¡ğ”¯16" => {
                    if result.ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾.is_some() {
                        return Some("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” duplicated address size.\");");
                    } else {
                        result.ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾ = core::num::NonZeroI8::new(16)
                    }
                }
                "ğ”ğ”¡ğ”¡ğ”¯32" => {
                    if result.ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾.is_some() {
                        return Some("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” duplicated address size.\");");
                    } else {
                        result.ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾ = core::num::NonZeroI8::new(32)
                    }
                }
                "ğ”ğ”¡ğ”¡ğ”¯64" => {
                    if result.ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾.is_some() {
                        return Some("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” duplicated address size.\");");
                    } else {
                        result.ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾ = core::num::NonZeroI8::new(64)
                    }
                }
                "ğ”¡ğ”ğ”±ğ”16" => {
                    if result.ğ–½ğ–ºğ—ğ–º_ğ—Œğ—‚ğ—“ğ–¾.is_some() {
                        return Some("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” duplicated data size.\");");
                    } else {
                        result.ğ–½ğ–ºğ—ğ–º_ğ—Œğ—‚ğ—“ğ–¾ = core::num::NonZeroI8::new(16)
                    }
                }
                "ğ”¡ğ”ğ”±ğ”32" => {
                    if result.ğ–½ğ–ºğ—ğ–º_ğ—Œğ—‚ğ—“ğ–¾.is_some() {
                        return Some("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” duplicated data size.\");");
                    } else {
                        result.ğ–½ğ–ºğ—ğ–º_ğ—Œğ—‚ğ—“ğ–¾ = core::num::NonZeroI8::new(32)
                    }
                }
                "â‚“ğ”¦ğ”·" => {
                    result.â‚“ğ—‚ğ—“ = match result.â‚“ğ—‚ğ—“ {
                        Some(count) => Some(count + 1),
                        None => Some(1),
                    }
                }
                "â‚áµ¥â‚“512" => {
                    if result.ğ–ºğ—ğ—‘ğŸ§ğŸ£ğŸ¤.is_some() {
                        return Some("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” duplicated â‚áµ¥â‚“512 marker.\");");
                    } else {
                        result.ğ–ºğ—ğ—‘ğŸ§ğŸ£ğŸ¤ = Some(true)
                    }
                }
                _ => return Some("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” unknown token.\");"),
            }
            None
        };
        for token_tree in input {
            match &token_tree {
                TokenTree::Ident(identifier) => {
                    if let Some(err) = process(identifier) {
                        return Err(err);
                    }
                }
                TokenTree::Group(group) if matches!(group.delimiter(), Delimiter::None) => {
                    for token_tree in group.stream().into_iter() {
                        if let TokenTree::Ident(identifier) = &token_tree {
                            if let Some(err) = process(identifier) {
                                return Err(err);
                            }
                        } else {
                            return Err("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” attributes group includes unknown item.\");");
                        }
                    }
                }
                _ => return Err("compile_error!(\"ğ–‹ğ–ğ–‘ğ–™ğ–Šğ–—_ğ–ğŸ´ğŸ²_ğ–’ğ–†ğ–—ğ–ğ–Šğ–—ğ–˜! â€” attributes group includes unknown item.\");"),
            }
        }
        Ok(result)
    }
}

fn filter_x86_markers_iterable(
    output: &mut impl Extend<TokenTree>,
    input: &mut impl Iterator<Item = TokenTree>,
    attributes: ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬,
) {
    let mut last_token: Option<TokenTree> = None;
    for token in input {
        if let Some(unwrapped_token) = last_token.take() {
            match token {
                TokenTree::Group(mut data_group_to_process) if matches!(data_group_to_process.delimiter(), Delimiter::Bracket) => {
                    match marker_is_compatible(unwrapped_token.to_string().as_ref(), attributes) {
                        (Some(true), attributes) => {
                            filter_x86_markers_iterable(output, &mut data_group_to_process.stream().into_iter(), attributes)
                        }
                        (Some(false), _) => (),
                        (None, _) => output.extend([
                            unwrapped_token,
                            filter_x86_markers_group(&mut data_group_to_process, attributes),
                        ]),
                    }
                }
                TokenTree::Group(mut data_group_to_process) => output.extend([
                    unwrapped_token,
                    filter_x86_markers_group(&mut data_group_to_process, attributes),
                ]),
                TokenTree::Ident(_) => {
                    output.extend([unwrapped_token]);
                    last_token = Some(token)
                }
                _ => output.extend([unwrapped_token, token]),
            }
        } else if let TokenTree::Ident(ident) = token {
            if ident.to_string() != "ğ•€ğ•Ÿğ•¤ğ•¥ğ•£ğ•¦ğ•”ğ•¥ğ•šğ• ğ•Ÿğ•¤ğ•€ğ•Ÿğ•¥ğ•–ğ•£ğ•—ğ•’ğ•”ğ•–" {
                last_token = Some(TokenTree::Ident(ident))
            } else {
                let additional_info: TokenStream = if attributes.ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾ != core::num::NonZeroI8::new(64) {
                    ğ”¦ğ”«ğ”°ğ”±ğ”¯ğ”²ğ” ğ”±ğ”¦ğ”¬ğ”«ğ”°_ğ”¦ğ”«ğ”£ğ”¬.0.parse().unwrap()
                } else {
                    ğ”¦ğ”«ğ”°ğ”±ğ”¯ğ”²ğ” ğ”±ğ”¦ğ”¬ğ”«ğ”°_ğ”¦ğ”«ğ”£ğ”¬.1.parse().unwrap()
                };
                output.extend(additional_info);
                last_token = None
            }
        } else if let TokenTree::Group(mut data_group_to_process) = token {
            output.extend([filter_x86_markers_group(&mut data_group_to_process, attributes)])
        } else {
            output.extend([token])
        }
    }
    if let Some(unwrapped_token) = last_token.take() {
        output.extend([unwrapped_token])
    }
}

fn filter_x86_markers_group(
    input: &mut Group, attributes: ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬
) -> TokenTree {
    let mut content = TokenStream::new();
    filter_x86_markers_iterable(&mut content, &mut input.stream().into_iter(), attributes);
    Group::new(input.delimiter(), content).into()
}

fn marker_is_compatible(
    marker: &str,
    attributes: ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬,
) -> (Option<bool>, ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬) {
    match marker {
        "â„œ16" => (Some(attributes.ğ–½ğ–ºğ—ğ–º_ğ—Œğ—‚ğ—“ğ–¾ == core::num::NonZeroI8::new(16)), attributes),
        "â„œ32" => (Some(attributes.ğ–½ğ–ºğ—ğ–º_ğ—Œğ—‚ğ—“ğ–¾ == core::num::NonZeroI8::new(32)), attributes),
        "Î16" => (Some(attributes.ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾ == core::num::NonZeroI8::new(16)), attributes),
        "Î32" => (Some(attributes.ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾ == core::num::NonZeroI8::new(32)), attributes),
        "Î86" => (Some(attributes.ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾ != core::num::NonZeroI8::new(64)), attributes),
        "Î64" => (Some(attributes.ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾ == core::num::NonZeroI8::new(64)), attributes),
        "Îğ”¦ğ”·" => match attributes.â‚“ğ—‚ğ—“ {
            None => (Some(false), attributes),
            Some(1) => (
                Some(true),
                ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬ {
                    ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾: attributes.ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾,
                    ğ–½ğ–ºğ—ğ–º_ğ—Œğ—‚ğ—“ğ–¾: attributes.ğ–½ğ–ºğ—ğ–º_ğ—Œğ—‚ğ—“ğ–¾,
                    â‚“ğ—‚ğ—“: None,
                    ğ–ºğ—ğ—‘ğŸ§ğŸ£ğŸ¤: attributes.ğ–ºğ—ğ—‘ğŸ§ğŸ£ğŸ¤,
                },
            ),
            Some(count) => (
                Some(true),
                ğšğ¬ğ¬ğğ¦ğ›ğ¥ğğ«_ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğğ¬ {
                    ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾: attributes.ğ–ºğ–½ğ–½ğ—‹_ğ—Œğ—‚ğ—“ğ–¾,
                    ğ–½ğ–ºğ—ğ–º_ğ—Œğ—‚ğ—“ğ–¾: attributes.ğ–½ğ–ºğ—ğ–º_ğ—Œğ—‚ğ—“ğ–¾,
                    â‚“ğ—‚ğ—“: Some(count - 1),
                    ğ–ºğ—ğ—‘ğŸ§ğŸ£ğŸ¤: attributes.ğ–ºğ—ğ—‘ğŸ§ğŸ£ğŸ¤,
                },
            ),
        },
        "Î§ğ”¦ğ”·" => (Some(attributes.â‚“ğ—‚ğ—“ == None), attributes),
        "Îğ”·ğ”·" => (Some(attributes.ğ–ºğ—ğ—‘ğŸ§ğŸ£ğŸ¤ == Some(true)), attributes),
        "Î§ğ”·ğ”·" => (Some(attributes.ğ–ºğ—ğ—‘ğŸ§ğŸ£ğŸ¤ != Some(true)), attributes),
        _ => (None, attributes),
    }
}

lazy_static! {
    static ref ğ”¦ğ”«ğ”°ğ”±ğ”¯ğ”²ğ” ğ”±ğ”¦ğ”¬ğ”«ğ”°_ğ”¦ğ”«ğ”£ğ”¬: (String, String) = get_instrution_info();
    static ref ğ”±ğ”ğ”¯ğ”¤ğ”¢ğ”±ğ”°_ğ”ªğ”ğ”­_ğ”©ğ”¢ğ”¤ğ”ğ” ğ”¶: std::collections::HashMap<&'static str, std::vec::Vec<&'static str>> = hashmap! {
        "reg8" => vec!["ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_8áµ‡â±áµ—"],
        "reg16" => vec!["ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_16áµ‡â±áµ—"],
        "reg32" => vec!["ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_32áµ‡â±áµ—"],
        "reg64" => vec![],
        "reg/acc8" => vec!["ğšğœğœğ®ğ¦ğ®ğ¥ğšğ­ğ¨ğ«_ğ«ğğ ğ¢ğ¬ğ­ğğ«_8áµ‡â±áµ—", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_8áµ‡â±áµ—"],
        "reg/acc16" => vec!["ğšğœğœğ®ğ¦ğ®ğ¥ğšğ­ğ¨ğ«_ğ«ğğ ğ¢ğ¬ğ­ğğ«_16áµ‡â±áµ—", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_16áµ‡â±áµ—"],
        "reg/acc32" => vec!["ğšğœğœğ®ğ¦ğ®ğ¥ğšğ­ğ¨ğ«_ğ«ğğ ğ¢ğ¬ğ­ğğ«_32áµ‡â±áµ—", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_32áµ‡â±áµ—"],
        "reg/acc64" => vec![],
    };
    static ref ğ”±ğ”ğ”¯ğ”¤ğ”¢ğ”±ğ”°_ğ”ªğ”ğ”­_ğ”µ86_64: std::collections::HashMap<&'static str, std::vec::Vec<&'static str>> = hashmap! {
        "reg8" => vec!["ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_8áµ‡â±áµ—â‚—â‚’", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_8áµ‡â±áµ—â‚™â‚’áµ£â‚‘â‚“", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_8áµ‡â±áµ—áµ£â‚‘â‚“"],
        "reg16" => vec!["ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_16áµ‡â±áµ—â‚™â‚’áµ£â‚‘â‚“", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_16áµ‡â±áµ—"],
        "reg32" => vec!["ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_32áµ‡â±áµ—â‚™â‚’áµ£â‚‘â‚“", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_32áµ‡â±áµ—"],
        "reg64" => vec!["ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_64áµ‡â±áµ—â‚™â‚’áµ£â‚‘â‚“", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_64áµ‡â±áµ—"],
        "reg/acc8" => vec!["ğšğœğœğ®ğ¦ğ®ğ¥ğšğ­ğ¨ğ«_ğ«ğğ ğ¢ğ¬ğ­ğğ«_8áµ‡â±áµ—", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_8áµ‡â±áµ—â‚—â‚’", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_8áµ‡â±áµ—â‚™â‚’áµ£â‚‘â‚“", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_8áµ‡â±áµ—áµ£â‚‘â‚“"],
        "reg/acc16" => vec!["ğšğœğœğ®ğ¦ğ®ğ¥ğšğ­ğ¨ğ«_ğ«ğğ ğ¢ğ¬ğ­ğğ«_16áµ‡â±áµ—", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_16áµ‡â±áµ—â‚™â‚’áµ£â‚‘â‚“", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_16áµ‡â±áµ—"],
        "reg/acc32" => vec!["ğšğœğœğ®ğ¦ğ®ğ¥ğšğ­ğ¨ğ«_ğ«ğğ ğ¢ğ¬ğ­ğğ«_32áµ‡â±áµ—", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_32áµ‡â±áµ—â‚™â‚’áµ£â‚‘â‚“", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_32áµ‡â±áµ—"],
        "reg/acc64" => vec!["ğšğœğœğ®ğ¦ğ®ğ¥ğšğ­ğ¨ğ«_ğ«ğğ ğ¢ğ¬ğ­ğğ«_64áµ‡â±áµ—", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_64áµ‡â±áµ—â‚™â‚’áµ£â‚‘â‚“", "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_64áµ‡â±áµ—"],
    };
        
}

#[tokio::main]
async fn get_instrution_info() -> (String, String) {
    let root_path = std::env::current_dir().expect("Obtaining crate root path");
    let root_path = root_path.to_str().expect("Turning crate root path into unicode string");
    // Note: during regular build root_path points to the yace workspace root, but in doctests
    // we get nested crate root.  Try to access both paths.
    let database_url = format!("sqlite:{}/test.db", root_path);
    let database_url_fallback = format!("sqlite:{}/../test.db", root_path);
    let mut pool = if let Ok(pool) = sqlx::SqliteConnection::connect(database_url.as_str()).await {
        pool
    } else {
        sqlx::SqliteConnection::connect(database_url_fallback.as_str())
            .await
            .expect("Failed to connect to test.db database")
    };
    let mut rows = sqlx::query("SELECT * FROM instructions")
        .fetch(&mut pool);
        let mut instruction_info_legacy = Vec::new();
        let mut instruction_info_x64 = Vec::new();
        while let Some (row) = rows.try_next().await.expect("Heh") {
        let instruction_name: &str =row.try_get("instruction_name").expect("whatever");
        let instruction_argument0: &str =row.try_get("instruction_argument0").expect("whatever");
        let instruction_argument1: &str =row.try_get("instruction_argument1").expect("whatever");
        if let Some(instruction_argument_cases0) = ğ”±ğ”ğ”¯ğ”¤ğ”¢ğ”±ğ”°_ğ”ªğ”ğ”­_ğ”©ğ”¢ğ”¤ğ”ğ” ğ”¶.get(instruction_argument0) {
            for instruction_argument_case0 in instruction_argument_cases0 {
                if let Some(instruction_argument_cases1) = ğ”±ğ”ğ”¯ğ”¤ğ”¢ğ”±ğ”°_ğ”ªğ”ğ”­_ğ”©ğ”¢ğ”¤ğ”ğ” ğ”¶.get(instruction_argument1) {
                    for instruction_argument_case1 in instruction_argument_cases1 {
                        instruction_info_legacy.push(format!("{}_ğ’‚ğ’”ğ’”ğ’†ğ’ğ’ƒğ’ğ’†ğ’“_ğ’Šğ’ğ’‘ğ’ğ’†ğ’ğ’†ğ’ğ’•ğ’‚ğ’•ğ’Šğ’ğ’<(Self::{}, Self::{})>", instruction_name, instruction_argument_case0, instruction_argument_case1));
                    }
                }
            }
        }
        if let Some(instruction_argument_cases0) = ğ”±ğ”ğ”¯ğ”¤ğ”¢ğ”±ğ”°_ğ”ªğ”ğ”­_ğ”µ86_64.get(instruction_argument0) {
            for instruction_argument_case0 in instruction_argument_cases0 {
                if let Some(instruction_argument_cases1) = ğ”±ğ”ğ”¯ğ”¤ğ”¢ğ”±ğ”°_ğ”ªğ”ğ”­_ğ”µ86_64.get(instruction_argument1) {
                    for instruction_argument_case1 in instruction_argument_cases1 {
                        if (*instruction_argument_case0 != "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_8áµ‡â±áµ—áµ£â‚‘â‚“" || *instruction_argument_case1 != "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_8áµ‡â±áµ—â‚™â‚’áµ£â‚‘â‚“") &&
                           (*instruction_argument_case0 != "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_8áµ‡â±áµ—â‚™â‚’áµ£â‚‘â‚“" || *instruction_argument_case1 != "ğ ğ©_ğ«ğğ ğ¢ğ¬ğ­ğğ«_8áµ‡â±áµ—áµ£â‚‘â‚“") {
                            instruction_info_x64.push(format!("{}_ğ’‚ğ’”ğ’”ğ’†ğ’ğ’ƒğ’ğ’†ğ’“_ğ’Šğ’ğ’‘ğ’ğ’†ğ’ğ’†ğ’ğ’•ğ’‚ğ’•ğ’Šğ’ğ’<(Self::{}, Self::{})>", instruction_name, instruction_argument_case0, instruction_argument_case1));
                        }
                    }
                }
            }
        }
    }
    (instruction_info_legacy.join(" + "), instruction_info_x64.join(" + "))
}
